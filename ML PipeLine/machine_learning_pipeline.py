# -*- coding: utf-8 -*-
"""Machine_Learning_Pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qq-yEVKgx2sfewJU0yibMQ2RfbJ76ByG

# Creating Machine Learning Pipeline
"""

from IPython.display import Image
Image(filename='/content/PipeLine.png')

#Filtering Warnings
import warnings
warnings.filterwarnings('ignore') # never print matching warnings

#importing packages
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""# Imporing packages and Data"""

#Importing Diabetes Data
DiabetesData = pd.read_csv("/content/pima-indians-diabetes.csv", header=None)

#Assigning column names
DiabetesData.columns = ["Pregnancies","Glucose","BloodPressure","SkinThickness","Insulin","BMI",
                        "DiabetesPedigreeFunction","Age","Class"]

#viewing Data
DiabetesData.head()

DiabetesData.iloc[:,[0,1,2,3,4,5,6,7]]

#Dividing Data in test and train
X_train, X_test, y_train, y_test = train_test_split(DiabetesData.iloc[:,[0,1,2,3,4,5,6,7]], DiabetesData.iloc[:,[8]], test_size=0.2, random_state=1)

"""# Creating pipelines """

## Creating pipelines for Logistic regression, Decision Tree and Random Forest models
#  Pipeline steps will include
## 1. Data Preprocessing using MinMax Scaler
## 2. Reducing Dimensionality using PCA
## 3. Training respective models

#Logistic Regression Pipeline
LogisticRegressionPipeline=Pipeline([('myscaler',MinMaxScaler()),
                     ('mypca',PCA(n_components=3)),
                     ('logistic_classifier',LogisticRegression())])

#Decision tree Pipeline
DecisionTreePipeline=Pipeline([('myscaler',MinMaxScaler()),
                     ('mypca',PCA(n_components=3)),
                     ('decisiontree_classifier',DecisionTreeClassifier())])

#Random Forest Pipeline
RandomForestPipeline=Pipeline([('myscaler',MinMaxScaler()),
                     ('mypca',PCA(n_components=3)),
                     ('randomforest_classifier',RandomForestClassifier())])

"""# model training and validation"""

## Defining the pipelines in a list
mypipeline = [LogisticRegressionPipeline, DecisionTreePipeline, RandomForestPipeline]

#Defining variables for choosing best model
accuracy=0.0
classifier=0
pipeline=""

# Creating dictionary of pipelines and training models
PipelineDict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest'}

# Fit the pipelines
for mypipe in mypipeline:
    mypipe.fit(X_train, y_train)

#getting test accuracy for all classifiers
for i,model in enumerate(mypipeline):
    # print("Model is: ",model)
    # print(model.score)
    print("{} Test Accuracy: {}".format(PipelineDict[i],model.score(X_test,y_test)))

#Choosing best model for the given data
for i,model in enumerate(mypipeline):
    if model.score(X_test,y_test)>accuracy:
        accuracy=model.score(X_test,y_test)
        pipeline=model
        classifier=i
print('Classifier with best accuracy:{}'.format(PipelineDict[classifier]))